{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":40704,"databundleVersionId":4467686,"sourceType":"competition"}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport torch.nn as nn\n# Activation Function\nimport torch.nn.functional as AF\n\n\n\n# custom dataset class for our image data\nclass BookCoverDataset(Dataset):\n    def __init__(self, csv_file_x,csv_file_y, root_dir, transforms=None):\n        \n        dataX= pd.read_csv(csv_file_x)\n        dataY= pd.read_csv(csv_file_y)\n        self.annotations=pd.merge(dataX, dataY, on='Id')\n        self.root_dir=root_dir\n        self.transforms=transforms\n        self.length=len(self.annotations)\n        \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,index):\n        imgPath=os.path.join(self.root_dir, self.annotations.iloc[index,1])\n        image=Image.open(imgPath)\n        y=torch.tensor(int(self.annotations.iloc[index,-1]))\n        if self.transforms:\n            image=self.transforms(image)\n        return (image,y)\n\n\ndef train(ep=5):\n    # Training loop\n    for epoch in range(ep):\n        for i, (img,target) in enumerate(train_loader):\n            img=img.to(device)\n            target=target.to(device)\n\n            out=model(img)\n            loss=lossFunction(out,target)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if(i%100==0):\n                print(loss.item())\n        print(f'epoch Finished: {loss.item()}')\n\ndef save(fileName):    \n    #saving the model\n    torch.save(model.state_dict(), fileName)  \n\ndef load(fileName):\n    #loading the model\n    state_dict = torch.load(fileName)\n    model.load_state_dict(state_dict)\n\ndef training_accuracy():\n    #Training accuracy    \n    correct=0\n    with torch.no_grad():\n        for i, (img,target) in enumerate(train_loader):\n            img=img.to(device)\n            target=target.to(device)\n            out=model(img)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(training_data))\n\ndef test_accuracy():\n    #Test accuracy\n    correct=0\n    with torch.no_grad():\n        for i, (img,target) in enumerate(test_loader):\n            img=img.to(device)\n            target=target.to(device)\n            out=model(img)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(testing_data))\n\n    \n\nbatch_size=32\n\n#calculated mean and std of the entire data separately\nmean=torch.tensor([0.5482, 0.5109, 0.4749])\nstd=torch.tensor([0.2526, 0.2428, 0.2356])\n\n# Defining a custom transform pipeline\ntrain_transform=transforms.Compose([\n    transforms.RandomInvert(0.6),\n    transforms.RandomSolarize(0.6),\n    transforms.ToTensor(),\n    transforms.ColorJitter(),\n    transforms.Normalize(mean=mean,std=std),\n])\n\ntest_transform=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean,std=std), \n])\n\n#Getting GPU support if available\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    \n    \n    \n# initializing cutom dataset\ntesting_data=BookCoverDataset(csv_file_x='/kaggle/input/col774-2022/non_comp_test_x.csv',\n                               csv_file_y='/kaggle/input/col774-2022/non_comp_test_y.csv',\n                               root_dir='/kaggle/input/col774-2022/images/images',\n                              transforms=test_transform)\n\ntraining_data=BookCoverDataset(csv_file_x='/kaggle/input/col774-2022/train_x.csv',\n                               csv_file_y='/kaggle/input/col774-2022/train_y.csv',\n                               root_dir='/kaggle/input/col774-2022/images/images',\n                               transforms=train_transform)\n\n\n# Dataloader for training dataset\ntrain_loader=DataLoader(dataset=training_data, batch_size=batch_size,shuffle=True)\n# Dataloader for testing dataset\ntest_loader=DataLoader(dataset=testing_data, batch_size=batch_size,shuffle=True)\n\n\n   \nmodel=torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\nnum_fters=model.fc.in_features\nmodel.fc=nn.Linear(num_fters, 30)\n# # freezing first 3 layers in RESNET\n# child_no=0\n# for child in model.children():\n#     child_no+=1\n#     if child_no<4:\n#         for param in child.parameters():\n#             param.requires_grad=False\n# load('cnn_with_dropout_and_regularization2')  \nmodel=model.to(device)\nlossFunction=nn.CrossEntropyLoss()\n# optimizer=torch.optim.SGD(model.parameters(), lr=0.0001)\noptimizer=torch.optim.Adam(model.parameters(), lr=0.0001)    \n \ntrain(ep=7)\nsave('cnn_with_dropout_and_regularization4')\ntraining_accuracy()    \ntest_accuracy()\n\n# 9627\n# 28.149122807017545\n# 1362\n# 23.894736842105264\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom transformers import BertModel\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport re\nfrom torch import nn\nimport torch\nimport os\nfrom PIL import Image\n\n\n# custom dataset class for our image data\nclass BookTitleDataset(Dataset):\n    def __init__(self, csv_file_x,csv_file_y,  tokenizer, max_title_len):\n        \n        dataX= pd.read_csv(csv_file_x)\n        dataY= pd.read_csv(csv_file_y)\n        data=pd.merge(dataX, dataY, on='Id')\n        del dataX\n        del dataY\n        title=data.iloc[:,2]\n        self.x=title\n        self.y=data.iloc[:,-1]\n#         self.vocab=vocab\n        self.tokenizer=tokenizer\n        self.length=len(self.y)\n        self.max_title_len=max_title_len\n        \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,index): \n        x=self.x[index]\n        y=self.y[index]\n        x=tokenizer(x,padding='max_length', max_length = self.max_title_len, truncation=True,\n                                return_tensors=\"pt\")\n        return (x,y)\n\n\nclass BertClassifier(nn.Module):\n\n    def __init__(self, dropout=0.3):\n\n        super(BertClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 30)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n\n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        final_layer = self.relu(linear_output)\n\n        return final_layer\n    \n\n\n# training\ndef train(ep=5):\n    for epoch in range(ep):\n        for i, (img,target) in enumerate(train_loader):\n    #         print(img.size())\n            target=target.to(device)\n            mask = img['attention_mask'].to(device)\n            input_id = img['input_ids'].squeeze(1).to(device)\n\n            out = model(input_id, mask)\n    #         out=model(img)\n            loss=lossFunction(out,target)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if(i%25==0):\n                print(loss.item())\n    #             print(out)\n        print(f'epoch Finished: {loss.item()}')\n\ndef save(name):\n    #saving the model\n    torch.save(model.state_dict(), name)  \n\ndef load(name):\n    #loading the model\n    state_dict = torch.load(name)\n    model.load_state_dict(state_dict)\n\ndef training_accuracy():\n    #Training accuracy    \n    correct=0\n    with torch.no_grad():\n        for i, (img,target) in enumerate(train_loader):\n            target=target.to(device)\n            mask = img['attention_mask'].to(device)\n            input_id = img['input_ids'].squeeze(1).to(device)\n\n            out = model(input_id, mask)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(training_data))\n\ndef test_accuracy(): \n    #Test accuracy\n    correct=0\n    with torch.no_grad():\n        for i, (img,target) in enumerate(test_loader):\n            target=target.to(device)\n            mask = img['attention_mask'].to(device)\n            input_id = img['input_ids'].squeeze(1).to(device)\n\n            out = model(input_id, mask)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(testing_data))\n\n\ndef predictions(root_dir, path, fileName):\n    dataX= pd.read_csv(path)\n    id=(dataX.iloc[:,0]).tolist()\n    predi=[]\n    title=dataX.iloc[:,2]\n    for i in range(len(title)):\n        image=tokenizer(title[i],padding='max_length', max_length = 61, truncation=True,\n                                return_tensors=\"pt\")\n#         image=image.to(device)\n        \n        mask = image['attention_mask'].to(device)\n        input_id = image['input_ids'].squeeze(1).to(device)\n\n        out = model(input_id, mask)\n        predi.append(torch.argmax(out).item())\n    data={'Id':id,'Genre':predi}\n    output=pd.DataFrame(data)\n    output.to_csv(fileName+'.csv', index=None)\n#         print(prediction)\n        \n\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nlearning_rate=5e-7\nbatch_size=32    \n    \ntraining_data=BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/train_x.csv',\n                               csv_file_y='/kaggle/input/col774-2022/train_y.csv',\n                               tokenizer=tokenizer, max_title_len=61)\n\ntesting_data=BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/non_comp_test_x.csv',\n                               csv_file_y='/kaggle/input/col774-2022/non_comp_test_y.csv',\n                               tokenizer=tokenizer, max_title_len=61)\n\ntrain_loader=DataLoader(dataset=training_data, batch_size=batch_size,shuffle=True)\ntest_loader=DataLoader(dataset=testing_data, batch_size=batch_size,shuffle=True)\n    \n\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel=BertClassifier()\nlossFunction=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\nload('ver3')\nmodel=model.to(device)\ntrain(ep=5)\ntest_accuracy()\npredictions(root_dir='/kaggle/input/col774-2022/images/images',path='/kaggle/input/col774-2022/comp_test_x.csv',fileName='file2')\nsave('ver4')\n\n# 21097\n# 61.687134502923975\n# 3109\n# 54.54385964912281\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport torch.nn as nn\n# Activation Function\nimport torch.nn.functional as AF\nfrom transformers import BertTokenizer\nfrom transformers import BertModel\nimport re\n\n\n\n# custom dataset class for our image data\nclass BookTitleDataset(Dataset):\n    def __init__(self, csv_file_x, csv_file_y, tokenizer, max_title_len, root_dir, transforms=None):\n        \n        dataX= pd.read_csv(csv_file_x)\n        dataY= pd.read_csv(csv_file_y)\n        data=pd.merge(dataX, dataY, on='Id')\n        del dataX\n        del dataY\n        title=data.iloc[:,2]\n        self.x=title\n        self.y=data.iloc[:,-1]\n#         self.vocab=vocab\n        self.tokenizer=tokenizer\n        self.length=len(self.y)\n        self.max_title_len=max_title_len\n        self.annotations=data\n        self.root_dir=root_dir\n        self.transforms=transforms\n        \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,index): \n        imgPath=os.path.join(self.root_dir, self.annotations.iloc[index,1])\n        image=Image.open(imgPath)\n        if self.transforms:\n            image=self.transforms(image)\n        x=self.x[index]\n        y=self.y[index]\n        x=tokenizer(x,padding='max_length', max_length = self.max_title_len, truncation=True,\n                                return_tensors=\"pt\")\n        return (image,x,y)\n    \n\n\nclass BertClassifier(nn.Module):\n\n    def __init__(self, dropout=0.3):\n\n        super(BertClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 256)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n\n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        final_layer = self.relu(linear_output)\n\n        return final_layer\n    \n        \n    \n    \nclass Res_Bert(nn.Module):\n    def __init__(self):\n        super(Res_Bert, self).__init__()\n        #Bert classifire\n        self.modelB = BertClassifier()\n        \n        model=torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n        num_fters=model.fc.in_features\n        model.fc=nn.Linear(num_fters, 256)\n        #ResNet\n        self.modelA = model\n        self.classifier = nn.Linear(512, 30)\n        \n    def forward(self, image, mask, input_id):\n        x1 = self.modelA(image)\n        x2 = self.modelB(input_id, mask)\n        x = torch.cat((x1, x2), dim=1)\n        x = self.classifier(AF.relu(x))\n        return x\n\n    \ndef train(ep=5):\n    # Training loop\n    for epoch in range(ep):\n        for i, (img, embed, target) in enumerate(train_loader):\n            img=img.to(device)\n            mask = embed['attention_mask'].to(device)\n            input_id = embed['input_ids'].squeeze(1).to(device)\n            target=target.to(device)\n\n            out=model(img, mask, input_id)\n            loss=lossFunction(out,target)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if(i%100==0):\n                print(loss.item())\n        print(f'epoch Finished: {loss.item()}')\n        \n        \ndef save(name):\n    #saving the model\n    torch.save(model.state_dict(), name)  \n\ndef load(name):\n    #loading the model\n    state_dict = torch.load(name)\n    model.load_state_dict(state_dict)\n\ndef training_accuracy():\n    #Training accuracy    \n    correct=0\n    with torch.no_grad():\n        for i, (img, embed, target) in enumerate(train_loader):\n            img=img.to(device)\n            mask = embed['attention_mask'].to(device)\n            input_id = embed['input_ids'].squeeze(1).to(device)\n            target=target.to(device)\n\n            out=model(img, mask, input_id)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(training_data))\n\ndef test_accuracy(): \n    #Test accuracy\n    correct=0\n    with torch.no_grad():\n        for i, (img, embed, target) in enumerate(test_loader):\n            img=img.to(device)\n            mask = embed['attention_mask'].to(device)\n            input_id = embed['input_ids'].squeeze(1).to(device)\n            target=target.to(device)\n\n            out=model(img, mask, input_id)\n    #         print(out)\n            for j in range(len(out)):\n    #             print(f'{torch.argmax(out[j])} : {target[j]}')\n                if torch.argmax(out[j]) == target[j]:\n                    correct+=1\n\n    print(correct)\n    print(correct*100/len(testing_data))\n\n\ndef predictions(root_dir, path, fileName):\n    dataX= pd.read_csv(path)\n    id=(dataX.iloc[:,0]).tolist()\n    predi=[]\n    title=dataX.iloc[:,2]\n    img_names=dataX.iloc[:,1]\n    for i in range(len(title)):\n        imgPath=os.path.join(root_dir, img_names[i])\n        image=Image.open(imgPath)\n        image=test_transform(image)\n        image=image.to(device)\n        embed=tokenizer(title[i],padding='max_length', max_length = 61, truncation=True,\n                                return_tensors=\"pt\")\n#         \n        mask = embed['attention_mask'].to(device)\n        input_id = embed['input_ids'].squeeze(1).to(device)\n\n        out=model(image.unsqueeze(0), mask, input_id)\n        predi.append(torch.argmax(out).item())\n    data={'Id':id,'Genre':predi}\n    output=pd.DataFrame(data)\n    output.to_csv(fileName+'.csv', index=None)\n\n    \n    \n    \ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nlearning_rate=5e-7\nbatch_size=32  \n\n#calculated mean and std of the entire data separately\nmean=torch.tensor([0.5482, 0.5109, 0.4749])\nstd=torch.tensor([0.2526, 0.2428, 0.2356])\n\n# Defining a custom transform pipeline\ntrain_transform=transforms.Compose([\n    transforms.RandomInvert(0.6),\n    transforms.RandomSolarize(0.6),\n    transforms.ToTensor(),\n    transforms.ColorJitter(),\n    transforms.Normalize(mean=mean,std=std),\n])\n\ntest_transform=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean,std=std), \n])\n\ntraining_data=BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/train_x.csv',\n                               csv_file_y='/kaggle/input/col774-2022/train_y.csv',\n                               root_dir='/kaggle/input/col774-2022/images/images',\n                               tokenizer=tokenizer, max_title_len=61, transforms=train_transform)\n\ntesting_data=BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/non_comp_test_x.csv',\n                              csv_file_y='/kaggle/input/col774-2022/non_comp_test_y.csv',\n                              root_dir='/kaggle/input/col774-2022/images/images',\n                              tokenizer=tokenizer, max_title_len=61, transforms=test_transform)\n\n\ntrain_loader=DataLoader(dataset=training_data, batch_size=batch_size,shuffle=True)\ntest_loader=DataLoader(dataset=testing_data, batch_size=batch_size,shuffle=True)    \n    \n    \ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel=Res_Bert()\nload('ver3')\nmodel=model.to(device)\nlossFunction=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n\ntrain(ep=1)\nsave('ver4')\n# load('ver1')\ntraining_accuracy()\ntest_accuracy()\n# predictions(root_dir='/kaggle/input/col774-2022/images/images',path='/kaggle/input/col774-2022/comp_test_x.csv',fileName='file2')\n\n# 28856\n# 84.37426900584795\n# 3254\n# 57.08771929824562","metadata":{"execution":{"iopub.status.busy":"2022-11-28T15:20:48.982079Z","iopub.execute_input":"2022-11-28T15:20:48.982473Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nUsing cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","output_type":"stream"},{"name":"stdout","text":"0.520939826965332\n0.39590370655059814\n0.36988842487335205\n0.8525664210319519\n0.5642260909080505\n0.3386771082878113\n0.7660030126571655\n0.5333539247512817\n0.31317538022994995\n0.42892882227897644\n0.5142131447792053\nepoch Finished: 0.49554121494293213\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as AF\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tqdm import tqdm  # Import tqdm for progress tracking\nimport re\n\n# Set random seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Custom dataset class for our image data\nclass BookTitleDataset(Dataset):\n    def __init__(self, csv_file_x, csv_file_y, tokenizer, max_title_len, root_dir, transforms=None):\n        dataX = pd.read_csv(csv_file_x)\n        dataY = pd.read_csv(csv_file_y)\n        data = pd.merge(dataX, dataY, on='Id')\n        del dataX\n        del dataY\n        title = data.iloc[:, 2]\n        self.x = title\n        self.y = data.iloc[:, -1]\n        self.tokenizer = tokenizer\n        self.length = len(self.y)\n        self.max_title_len = max_title_len\n        self.annotations = data\n        self.root_dir = root_dir\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, index): \n        imgPath = os.path.join(self.root_dir, self.annotations.iloc[index, 1])\n        image = Image.open(imgPath)\n        if self.transforms:\n            image = self.transforms(image)\n        x = self.x[index]\n        y = self.y[index]\n        x = self.tokenizer(x, padding='max_length', max_length=self.max_title_len, truncation=True,\n                           return_tensors=\"pt\")\n        return (image, x, y)\n\nclass BertClassifier(nn.Module):\n    def __init__(self, dropout=0.3):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 256)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        final_layer = self.relu(linear_output)\n        return final_layer\n\nclass Res_Bert(nn.Module):\n    def __init__(self):\n        super(Res_Bert, self).__init__()\n        self.modelB = BertClassifier()\n        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n        num_fters = model.fc.in_features\n        model.fc = nn.Linear(num_fters, 256)\n        self.modelA = model\n        self.classifier = nn.Linear(512, 30)\n\n    def forward(self, image, mask, input_id):\n        x1 = self.modelA(image)\n        x2 = self.modelB(input_id, mask)\n        x = torch.cat((x1, x2), dim=1)\n        x = self.classifier(AF.relu(x))\n        return x\n\ndef train(ep=5):\n    # Training loop\n    for epoch in range(ep):\n        model.train()\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{ep}\")\n        for i, (img, embed, target) in enumerate(pbar):\n            img = img.to(device)\n            mask = embed['attention_mask'].to(device)\n            input_id = embed['input_ids'].squeeze(1).to(device)\n            target = target.to(device)\n\n            out = model(img, mask, input_id)\n            loss = lossFunction(out, target)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            pbar.set_postfix({'loss': loss.item()})\n\n        print(f'Epoch {epoch + 1} finished with loss: {loss.item()}')\n\ndef save(name):\n    # Saving the model\n    torch.save(model.state_dict(), name)  \n\ndef load(name):\n    # Loading the model\n    state_dict = torch.load(name)\n    model.load_state_dict(state_dict)\n\ndef calculate_metrics(loader):\n    all_preds = []\n    all_targets = []\n    model.eval()\n    with torch.no_grad():\n        for img, embed, target in tqdm(loader, desc=\"Calculating Metrics\"):\n            img = img.to(device)\n            mask = embed['attention_mask'].to(device)\n            input_id = embed['input_ids'].squeeze(1).to(device)\n            target = target.to(device)\n\n            out = model(img, mask, input_id)\n            all_preds.extend(torch.argmax(out, dim=1).cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n    return np.array(all_targets), np.array(all_preds)\n\ndef print_metrics(y_true, y_pred):\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_true, y_pred))\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_true, y_pred))\n\n# Predictions function\ndef predictions(root_dir, path, fileName):\n    dataX = pd.read_csv(path)\n    id = (dataX.iloc[:, 0]).tolist()\n    predi = []\n    title = dataX.iloc[:, 2]\n    img_names = dataX.iloc[:, 1]\n    for i in range(len(title)):\n        imgPath = os.path.join(root_dir, img_names[i])\n        image = Image.open(imgPath)\n        image = test_transform(image)\n        image = image.to(device)\n        embed = tokenizer(title[i], padding='max_length', max_length=61, truncation=True,\n                          return_tensors=\"pt\")\n        \n        mask = embed['attention_mask'].to(device)\n        input_id = embed['input_ids'].squeeze(1).to(device)\n\n        out = model(image.unsqueeze(0), mask, input_id)\n        predi.append(torch.argmax(out).item())\n    data = {'Id': id, 'Genre': predi}\n    output = pd.DataFrame(data)\n    output.to_csv(fileName + '.csv', index=None)\n\n# Setup\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nlearning_rate = 5e-7\nbatch_size = 32  \n\n# Calculated mean and std of the entire data separately\nmean = torch.tensor([0.5482, 0.5109, 0.4749])\nstd = torch.tensor([0.2526, 0.2428, 0.2356])\n\n# Defining a custom transform pipeline\ntrain_transform = transforms.Compose([\n    transforms.RandomInvert(0.6),\n    transforms.RandomSolarize(0.6),\n    transforms.ToTensor(),\n    transforms.ColorJitter(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std), \n])\n\ntraining_data = BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/train_x.csv',\n                                  csv_file_y='/kaggle/input/col774-2022/train_y.csv',\n                                  root_dir='/kaggle/input/col774-2022/images/images',\n                                  tokenizer=tokenizer, max_title_len=61, transforms=train_transform)\n\ntesting_data = BookTitleDataset(csv_file_x='/kaggle/input/col774-2022/non_comp_test_x.csv',\n                                 csv_file_y='/kaggle/input/col774-2022/non_comp_test_y.csv',\n                                 root_dir='/kaggle/input/col774-2022/images/images',\n                                 tokenizer=tokenizer, max_title_len=61, transforms=test_transform)\n\ntrain_loader = DataLoader(dataset=training_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=testing_data, batch_size=batch_size, shuffle=True)    \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Res_Bert()\nload('ver4')\nmodel = model.to(device)\nlossFunction = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\ntrain(ep=10)\nsave('ver5')\n\n# Calculate training and testing accuracy and metrics\ny_true_train, y_pred_train = calculate_metrics(train_loader)\nprint(\"Training Metrics:\")\nprint_metrics(y_true_train, y_pred_train)\n\ny_true_test, y_pred_test = calculate_metrics(test_loader)\nprint(\"Testing Metrics:\")\nprint_metrics(y_true_test, y_pred_test)\n\n# Predictions\n# predictions(root_dir='/kaggle/input/col774-2022/images/images', path='/kaggle/input/col774-2022/comp_test_x.csv', fileName='file2')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:41:01.319995Z","iopub.execute_input":"2024-09-27T12:41:01.320370Z","iopub.status.idle":"2024-09-27T14:25:39.943439Z","shell.execute_reply.started":"2024-09-27T12:41:01.320339Z","shell.execute_reply":"2024-09-27T14:25:39.942381Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nUsing cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\nEpoch 1/10: 100%|██████████| 1069/1069 [10:21<00:00,  1.72it/s, loss=2.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished with loss: 2.5458555221557617\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 1069/1069 [09:49<00:00,  1.81it/s, loss=2.34]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished with loss: 2.3439829349517822\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 1069/1069 [09:51<00:00,  1.81it/s, loss=2.04]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished with loss: 2.040240526199341\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 1069/1069 [09:49<00:00,  1.81it/s, loss=2.21]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished with loss: 2.210505962371826\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 1069/1069 [09:54<00:00,  1.80it/s, loss=2.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished with loss: 2.3855602741241455\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 1069/1069 [09:58<00:00,  1.79it/s, loss=2.28]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished with loss: 2.2802858352661133\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 1069/1069 [09:53<00:00,  1.80it/s, loss=2.22]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished with loss: 2.2200396060943604\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 1069/1069 [09:47<00:00,  1.82it/s, loss=2.14]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished with loss: 2.1417338848114014\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 1069/1069 [09:47<00:00,  1.82it/s, loss=2.32]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished with loss: 2.315274953842163\n","output_type":"stream"},{"name":"stderr","text":"Calculating Metrics: 100%|██████████| 1069/1069 [04:38<00:00,  3.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Metrics:\nConfusion Matrix:\n[[ 903   17    0    8    4    3   25    2    7    0    3    5   17    1\n     2   17   12    0   37    0    6    0    9   45    2    1    3    4\n     1    0]\n [  11  666    8   25    9   14   43   12    7    2   12   38   22    6\n     0   11    4    4    2    0   12    1   82   12   10    9  100   14\n     8   11]\n [   0    3  690   18   18    1    1    4    1    1   11    2    0    4\n     0    1    2    7    0    3    5    1    4    0   76    5    7   85\n     3  195]\n [   0   14   25  774    7    1    0    7    1    1    9    1    1    6\n     1    0    1    4    0    0   15    2    4    6  108   28   39   27\n     7   27]\n [   0    0   18    1  675    2    0   25    4    7   45    0    3   21\n    13    1    2  227    0    6    5    0    0    2   17    8    1   18\n     4   28]\n [  10    5    1    0    6  850    1   20    6  109   10    4   39    2\n     3    0   23    1   23    0    2    0    6   22    1    0    1    3\n     1    4]\n [ 116   39    2    3    5   19  594    0    4    1    2   14  121   15\n     0   45   17    0   25    0    1    0   11   24    2    2   19    6\n    41    4]\n [   2    4   22    5   23   25    1  571    9  155  143    3    1   10\n    15    4   16    9    2    5    8    5   11    5    3   19    3   26\n     4   23]\n [  22   27    5   20   40   14   22   25  451   10   32   28   22   20\n    14   10   34   22   52    5   19    1   10   43   10   16   17   26\n   121   11]\n [   1    8    8    1   14  148    2   76    3  606   67   26    5    5\n    11    1    6    9    6    3    7    2   81   13    5    4    7    7\n     9    3]\n [   3    6   15    4   76   19    0  156   23  150  474    5    4    3\n    23    5    9   27    6    7    6    1    8   31    7    6   11   18\n     1   25]\n [   4   20   17   12    1    5   17    5    1    3    6  784   35    6\n     1    4    4    1   10    6   20    0   14    6   12    6   18   16\n    82   19]\n [  36   20    2    8    7   59   15    6    4   15    5   20  764   19\n     9    9   20    3   19    1    2    1   13   20    3    4   13   17\n    53    8]\n [   0    4    2    3   87    1    4    1    4    1    2    0    5  713\n    29    1   67   56    1    8    0    1    2    2    4    1    6   17\n    71   14]\n [  11    4   15    4  143   19    1   53   15   29   72    6   15  115\n   243    0   95   80    6   13    2    3    3   58    6   11   19   24\n    15   18]\n [   2    8    1    1    2    1    8    1    1    0    1    5    1    0\n     0 1097    0    0    0    1    1    0    1    0    2    1    3    3\n     8    0]\n [   8    0    1    1   13   19    5    9    2    9    4    3    4   45\n    15    1  931    2    4    3    0    0    0   38    1    0    2    6\n     6    4]\n [   0    0    9    5  474    0    0   22    4    8   39    6    5   37\n    23    6    6  399    0    1    2    0    0    4   22    7    6   17\n     5   14]\n [  26    2    0    2    0   35   23    9   25    1    3    2   23    3\n     1    5   36    3  903    0    1    0    0   27    0    2    2    1\n    11    0]\n [   0    3   85   14  102    8    3   35    4   14   53   58    5  212\n    26    0   39   41    2  122   16    7    9   14   20    8   37   73\n    41  105]\n [  13   73   60  123   25    6    5   36   16   16   40   75   22    9\n     7    8   10    4    6    9  171    6   52   22   36   32  129   49\n    18   71]\n [  10   12  157   64   48    9    4   86   26   35   62   35   15   49\n    20    1    9   23   18   19   17   23   17    9   74   24   36   82\n    12  104]\n [   0   18    4    4    1    4    1    2    1   26    4    4    1    2\n     0    0    2    0    0    0    2    0 1013    1    2    4    9    1\n     6    4]\n [  57   17    1    4   10   27   16    9   14   13   18   11   24   18\n     8    1   79    4   34    1    2    0    7  757    0    0   14    0\n    10    2]\n [   1    5  128  105   13    1    2    0    1    1    5    1    4    6\n     5    0    1    2    0    2    3    0    3    0  553    3    6  113\n     6  202]\n [  22   53   59  164   21    2   17   31   22    2    9   55   33   48\n     1    3    7   29    5   13   34    4   18    6   96  210   39   59\n    26   44]\n [  24  185   33   63    8    3   39    4    8    3   10   17   12   16\n     1   11    4    5    1    7   28    3    5   20   19    8  505   29\n    41   23]\n [   0    3  129   28   77    1    0    3   12    4   22    0    4   16\n     7    2    4   36    0   14   11    3    7    2   89   14   16  374\n     9  281]\n [   1   14    7    6    6    2    9    6   14    1    3   25   14   30\n     1   11   22    8    3    5    1    0   20    6    2    0   15   18\n   909   10]\n [   0    0  114   15   14    0    0    4    1    2    8    1    3    4\n     4    0    6    4    0    3    3    1    1    1   72    3    6  112\n     3  768]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.70      0.80      0.75      1134\n           1       0.54      0.58      0.56      1155\n           2       0.43      0.60      0.50      1148\n           3       0.52      0.69      0.60      1116\n           4       0.35      0.60      0.44      1133\n           5       0.65      0.74      0.69      1153\n           6       0.69      0.52      0.60      1132\n           7       0.47      0.50      0.49      1132\n           8       0.65      0.39      0.49      1149\n           9       0.49      0.53      0.51      1144\n          10       0.40      0.42      0.41      1129\n          11       0.64      0.69      0.66      1135\n          12       0.62      0.65      0.64      1175\n          13       0.49      0.64      0.56      1107\n          14       0.50      0.22      0.31      1098\n          15       0.87      0.95      0.91      1149\n          16       0.63      0.82      0.72      1136\n          17       0.40      0.36      0.37      1121\n          18       0.78      0.79      0.78      1146\n          19       0.47      0.11      0.17      1156\n          20       0.43      0.15      0.22      1149\n          21       0.35      0.02      0.04      1100\n          22       0.72      0.91      0.80      1116\n          23       0.63      0.65      0.64      1158\n          24       0.44      0.47      0.46      1172\n          25       0.48      0.19      0.27      1132\n          26       0.46      0.44      0.45      1135\n          27       0.30      0.32      0.31      1168\n          28       0.59      0.78      0.67      1169\n          29       0.38      0.67      0.48      1153\n\n    accuracy                           0.54     34200\n   macro avg       0.54      0.54      0.52     34200\nweighted avg       0.54      0.54      0.52     34200\n\n","output_type":"stream"},{"name":"stderr","text":"Calculating Metrics: 100%|██████████| 179/179 [00:50<00:00,  3.51it/s]","output_type":"stream"},{"name":"stdout","text":"Testing Metrics:\nConfusion Matrix:\n[[125   6   0   1   0   1   4   1   1   0   0   2   4   0   0   1   2   0\n    2   1   0   0   1   6   1   0   1   2   0   0]\n [  4 105   0   0   1   4   8   6   1   0   3   6   3   1   1   2   0   2\n    1   1   1   0  10   4   1   1  17   1   2   3]\n [  0   1  91   3   7   0   0   2   0   0   1   1   1   1   0   0   0   0\n    0   0   1   0   1   0  15   1   2  17   2  37]\n [  0   4  13 131   1   2   0   4   1   1   0   2   0   0   0   0   0   3\n    0   1   5   0   4   1  24   2   6   6   0   5]\n [  0   1   1   2  95   0   1   4   0   1  11   0   0   4   1   0   0  45\n    0   1   0   1   2   1   1   3   1   5   0   3]\n [  0   3   0   0   2 106   0   2   0  12   3   2   5   0   3   0   2   0\n    6   0   0   0   2   0   1   0   1   0   0   0]\n [ 20   9   0   1   3   5 103   1   0   0   1   1  21   1   0   4   1   0\n    4   0   0   0   2   8   4   0   5   0  13   2]\n [  0   3   5   2   5   3   0  85   1  16  26   3   1   2   0   0   1   1\n    2   2   0   0   2   0   0   2   1   1   0   4]\n [  5   5   1   4  11   5   3   6  55   3   6   6   3   4   7   0   4   7\n    6   1   3   0   1   8   4   4   3   6  22   5]\n [  2   2   3   0   1  27   0  16   1  84  18   6   2   0   3   1   2   0\n    1   0   4   0  18   1   0   0   4   2   1   0]\n [  3   5   4   1  18   8   1  32   3  26  83   0   2   1   2   1   1   5\n    1   1   2   0   1   7   0   1   0   4   0   4]\n [  2   2   3   1   0   1   3   5   0   1   1 115  10   1   0   0   0   1\n    0   1   3   0   2   1   4   2   5   4  16   1]\n [  4   3   1   0   4   7   2   2   1   1   4   5 103   4   5   0   3   1\n    2   0   1   0   8   5   2   0   2   3  12   1]\n [  0   2   4   1  12   2   4   3   2   0   1   3   5 104   1   0   8  16\n    0   1   0   0   2   2   1   0   3   5  16   5]\n [  0   2   4   1  16   5   0   7   3   8  18   1   7  14  28   1  13   9\n    1   1   1   2   0  13   3   1   3   7   3   5]\n [  1   1   0   0   0   0   1   0   0   1   0   1   0   0   0 185   0   0\n    0   0   0   0   0   0   0   1   1   0   1   1]\n [  3   2   0   1   6   3   1   1   0   2   1   0   1   8   4   0 148   2\n    1   2   0   0   0   2   1   0   1   0   1   2]\n [  0   1   0   0  88   0   0   3   1   2   6   0   3   7   3   0   0  53\n    0   0   0   0   0   0   5   1   1  13   1  10]\n [  6   2   0   0   1   6   4   1   3   1   1   0   4   1   1   0   4   0\n  138   0   0   0   0   1   0   0   0   0   0   1]\n [  1   0  16   2  18   2   0   5   1   2   8  14   2  35   2   1   5   8\n    0  20   4   3   2   1   4   1   3  15  10  17]\n [  7  12   8  15   5   1   2   4   2   2   7  12   7   3   1   3   1   0\n    0   4  30   1   2   6   6   4  17  10   3  15]\n [  0   6  25  10  10   2   1  15   2  13  10   8   1   8   2   0   0  10\n    8   1   4   5   1   1  16   2  10  16   4  13]\n [  0   4   2   1   1   0   0   0   0  10   0   1   0   1   1   0   0   0\n    0   0   0   0 185   0   1   3   0   1   1   0]\n [  8   5   1   0   1   2   3   3   5   1   1   2   6   5   1   0  23   1\n    9   0   0   0   0 104   0   0   3   1   2   1]\n [  2   2  25  15   1   0   0   0   0   0   0   0   1   1   0   1   0   3\n    0   0   2   0   1   0  61   1   1  11   3  27]\n [  3   7  22  28   4   0   2   4   1   0   0   8   6   5   0   2   1  11\n    3   4   7   1   2   0  19  33   6  10   4   7]\n [  6  41   2   7   2   0   5   4   0   2   0   5   1   3   1   2   2   4\n    2   2   5   0   2   3   3   1  71   8   5   9]\n [  0   0  29   5  11   0   0   3   2   2   9   2   0   4   4   0   3   6\n    0   0   3   0   0   0  14   1   0  56   4  39]\n [  3   1   0   0   3   2   1   0   4   0   1   4   0   8   0   5   6   1\n    0   0   0   0   1   1   0   2   2   1 118   1]\n [  0   0  20   2   0   0   0   0   0   1   5   0   1   2   0   0   1   0\n    0   1   0   0   1   0  11   0   1  21   0 132]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.61      0.77      0.68       162\n           1       0.44      0.56      0.49       189\n           2       0.33      0.49      0.39       184\n           3       0.56      0.61      0.58       216\n           4       0.29      0.52      0.37       184\n           5       0.55      0.71      0.62       150\n           6       0.69      0.49      0.58       209\n           7       0.39      0.51      0.44       168\n           8       0.61      0.28      0.38       198\n           9       0.44      0.42      0.43       199\n          10       0.37      0.38      0.38       217\n          11       0.55      0.62      0.58       185\n          12       0.52      0.55      0.53       186\n          13       0.46      0.51      0.48       203\n          14       0.39      0.16      0.23       177\n          15       0.89      0.95      0.92       194\n          16       0.64      0.77      0.70       193\n          17       0.28      0.27      0.27       198\n          18       0.74      0.79      0.76       175\n          19       0.44      0.10      0.16       202\n          20       0.39      0.16      0.23       190\n          21       0.38      0.02      0.05       204\n          22       0.73      0.87      0.80       212\n          23       0.59      0.55      0.57       188\n          24       0.30      0.39      0.34       158\n          25       0.49      0.17      0.25       200\n          26       0.42      0.36      0.38       198\n          27       0.25      0.28      0.26       197\n          28       0.48      0.72      0.58       165\n          29       0.38      0.66      0.48       199\n\n    accuracy                           0.48      5700\n   macro avg       0.49      0.49      0.46      5700\nweighted avg       0.49      0.48      0.46      5700\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}